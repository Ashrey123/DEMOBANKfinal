
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.impute import SimpleImputer

# Load the data
data = pd.read_csv('D:\\python\\final.csv')

# Concatenate the relevant columns into a 'text' column
data['text'] = data['Employee_Name'] + ' ' + data['Skills'] + ' ' + data['Job _Title'] + ' ' + data['Reviews']

# Prepare the features and target variables
X = data['text']
y = data['Positive_feedback']

# Impute missing values in the target variable
imputer = SimpleImputer(strategy='most_frequent')
y = imputer.fit_transform(y.values.reshape(-1, 1))

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)

# Vectorize the training data
vectorizer = CountVectorizer()
X_train_vectorized = vectorizer.fit_transform(X_train)

# Train the logistic regression model
model = LogisticRegression()
model.fit(X_train_vectorized, y_train)

# Vectorize the testing data and evaluate the model accuracy
X_test_vectorized = vectorizer.transform(X_test)
accuracy = model.score(X_test_vectorized, y_test)

# Define the AI interface
while True:
    user_input = input("Enter the text (or 'q' to quit): ")
    
    if user_input.lower() == 'q':
        break
    
    # Vectorize the user input
    user_input_vectorized = vectorizer.transform([user_input])
    
    # Predict the positive feedback
    prediction = model.predict(user_input_vectorized)
    
    print("Predicted Positive Feedback:", prediction[0])

print("Exiting the program.")

